import time
import random
import csv
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC


CSV_FILE = "kcar_cars.csv"
MAX_PAGES = 500  # í¬ë¡¤ë§í•  í˜ì´ì§€ ìˆ˜
BASE_URL = "https://www.kcar.com/bc/search"

def init_driver(headless=True):
    """Selenium Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™”"""
    options = Options()
    if headless:
        options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/118.0 Safari/537.36"
    )
    
    driver = webdriver.Chrome(options=options)
    return driver

def get_car_info(driver):
    """í˜„ì¬ í˜ì´ì§€ì—ì„œ ì°¨ëŸ‰ëª…, ì—°ì‹, ì£¼í–‰ê±°ë¦¬, ê°€ê²©ì„ ì¶”ì¶œ"""
    car_data = []
    car_boxes = driver.find_elements(By.CSS_SELECTOR, "div.carListBox")
    
    for box in car_boxes:
        try:
            name = box.find_element(By.CSS_SELECTOR, "div.carName p.carTit a").text.strip()
            detail_elem = box.find_element(By.CSS_SELECTOR, "p.detailCarCon")
            spans = detail_elem.find_elements(By.TAG_NAME, "span")
            
            year = spans[0].text.strip() if len(spans) > 0 else ""
            mileage = spans[1].text.strip() if len(spans) > 1 else ""
            price = box.find_element(By.CSS_SELECTOR, "div.carExpIn p.carExp").text.strip()
            
            car_data.append([name, year, mileage, price])
        except Exception:
            continue
    return car_data

def get_car_models(driver):
    """_001~_007 ì ‘ë‘ì‚¬ë³„ë¡œ ì°¨ëŸ‰ ëª¨ë¸ëª…ì„ 7ê°œì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
    models_001, models_002, models_003, models_004, models_005, models_006, models_007 = [], [], [], [], [], [], []
    labels = driver.find_elements(By.CSS_SELECTOR, "label.el-checkbox")
    
    for label in labels:
        try:
            label_id = label.get_attribute("id")
            if label_id:
                label_id = label_id.strip()  # ê³µë°± ì œê±°
                model_name = label.find_element(By.CLASS_NAME, "el-checkbox__label").text.strip()
                if model_name:
                    if label_id.startswith("_001"):
                        models_001.append(model_name)
                    elif label_id.startswith("_002"):
                        models_002.append(model_name)
                    elif label_id.startswith("_003"):
                        models_003.append(model_name)
                    elif label_id.startswith("_004"):
                        models_004.append(model_name)
                    elif label_id.startswith("_005"):
                        models_005.append(model_name)
                    elif label_id.startswith("_006"):
                        models_006.append(model_name)
                    elif label_id.startswith("_007"):
                        models_007.append(model_name)
        except Exception:
            continue

    models = [models_001, models_002, models_003, models_004, models_005, models_006, models_007]
    
    return models

def get_checked_car_models(driver):
    """_001~_007 ì ‘ë‘ì‚¬ ì°¨ëŸ‰ ì¤‘ ì²´í¬ëœ ëª¨ë¸ëª…ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
    all_models = []
    labels = driver.find_elements(By.CSS_SELECTOR, "label.el-checkbox")
    
    for label in labels:
        try:
            label_id = label.get_attribute("id").strip()
            # _001~_007 ì ‘ë‘ì‚¬ ì²´í¬
            if label_id.startswith(("_001", "_002", "_003", "_004", "_005", "_006", "_007")):
                # ì²´í¬ ìƒíƒœ í™•ì¸
                input_span = label.find_element(By.CSS_SELECTOR, "span.el-checkbox__input")
                if "is-checked" in input_span.get_attribute("class"):
                    model_name = label.find_element(By.CLASS_NAME, "el-checkbox__label").text.strip()
                    if model_name:
                        all_models.append(model_name)
        except Exception:
            continue
    
    return all_models

def crawl_car_info(base_url, max_pages=5, csv_file=CSV_FILE):
    """ì°¨ëŸ‰ ì •ë³´(ì°¨ëŸ‰ëª…, ì—°ì‹, ì£¼í–‰ê±°ë¦¬, ê°€ê²©)ë¥¼ ë²„íŠ¼ í´ë¦­ìœ¼ë¡œ í˜ì´ì§€ë¥¼ ë„˜ê¸°ë©° í¬ë¡¤ë§ í›„ CSV ì €ì¥"""
    driver = init_driver()
    driver.get(base_url)
    time.sleep(random.uniform(3, 6))

    with open(csv_file, mode="w", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        writer.writerow(["ì°¨ëŸ‰ëª…", "ì—°ì‹", "ì£¼í–‰ê±°ë¦¬", "ê°€ê²©"])

    for page in range(1, max_pages + 1):
        print(f"\n=== ğŸ“„ Page {page} ===")
        cars = get_car_info(driver)
        for car in cars:
            with open(csv_file, mode="a", newline="", encoding="utf-8-sig") as f:
                writer = csv.writer(f)
                writer.writerow(car)

        try:
            wait = WebDriverWait(driver, 10)

            # iframe ì „í™˜ ë¶€ë¶„ ì œê±°
            # â†’ ë²„íŠ¼ì€ iframe ì•ˆì´ ì•„ë‹ˆë¼ ë©”ì¸ DOMì— ìˆëŠ” ê²½ìš°ê°€ ë§ìŒ

            # "ë‹¤ìŒ" ë²„íŠ¼ ì°¾ê¸° (í…ìŠ¤íŠ¸ or alt ì†ì„± ê¸°ë°˜)
            next_btn = wait.until(EC.element_to_be_clickable(
                (By.XPATH, "//button[contains(., 'ë‹¤ìŒ') or .//img[contains(@alt, 'ë‹¤ìŒ')]]")
            ))

            # disabled ì—¬ë¶€ í™•ì¸
            if "is-disabled" in next_btn.get_attribute("class"):
                print("ë§ˆì§€ë§‰ í˜ì´ì§€ì…ë‹ˆë‹¤. í¬ë¡¤ë§ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            # JavaScriptë¡œ í´ë¦­ (ë” ì•ˆì •ì )
            driver.execute_script("arguments[0].click();", next_btn)
            print("ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ í´ë¦­ ì„±ê³µ.")

            time.sleep(random.uniform(3, 5))

        except Exception as e:
            print(f"ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")

            # ë””ë²„ê¹…ìš©: ë²„íŠ¼ í›„ë³´ ì¶œë ¥
            buttons = driver.find_elements(By.TAG_NAME, "button")
            print("ë²„íŠ¼ ëª©ë¡:")
            for b in buttons:
                print(b.get_attribute("outerHTML")[:200])  # ì•ë¶€ë¶„ë§Œ ì¶œë ¥

            break

    driver.quit()
    print(f"\nâœ… ì°¨ëŸ‰ ì •ë³´ í¬ë¡¤ë§ ì™„ë£Œ! ë°ì´í„°ê°€ '{csv_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def crawl_car_models(base_url):
    """ëª¨ë¸ëª…ì„ í˜ì´ì§€ë³„ë¡œ ìˆ˜ì§‘í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
    driver = init_driver()
    
    driver.get(base_url)
    time.sleep(random.uniform(3, 6))
    
    models = get_car_models(driver)
    
    driver.quit()
    print(f"\nâœ… ëª¨ë¸ëª… í¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(models)}ê°œ ëª¨ë¸ ìˆ˜ì§‘")
    return sorted(models)

if __name__ == "__main__":
    # 1ï¸âƒ£ ì°¨ëŸ‰ ì •ë³´ í¬ë¡¤ë§ ì‹¤í–‰
    crawl_car_info(BASE_URL, MAX_PAGES)

